import { v4 as uuidv4 } from 'uuid';
import { H3Error } from 'h3';
import { 
  DEFAULT_TTS_CONFIG, 
  validateTTSParams,
  enhanceTextWithSSML,
  validateAndCleanSSML,
  getSSMLRecommendationForPodcast
} from '../config/volcengineTTSConfig';

// --- Interfaces based on Volcengine TTS API ---

interface VolcengineAppConfig {
  appid: string;
  token: string; // This is the Access Token
  cluster: string;
}

interface VolcengineUserConfig {
  uid: string;
}

interface VolcengineAudioConfig {
  voice_type: string;
  encoding: 'mp3' | 'pcm' | 'wav';
  speed_ratio?: number;
  volume_ratio?: number;
  pitch_ratio?: number;
  emotion?: string;        // éŸ³è‰²æƒ…æ„Ÿï¼Œå¦‚ "happy", "sad", "angry", "neutral" ç­‰
  enable_emotion?: boolean; // æ˜¯å¦å¯ç”¨éŸ³è‰²æƒ…æ„Ÿ
  emotion_scale?: number;   // æƒ…ç»ªå€¼è®¾ç½®ï¼ŒèŒƒå›´1~5ï¼Œé»˜è®¤4ï¼Œæ•°å€¼è¶Šå¤§æƒ…æ„Ÿè¶Šæ˜æ˜¾
  loudness_ratio?: number;  // éŸ³é‡è°ƒèŠ‚ï¼ŒèŒƒå›´[0.5,2]ï¼Œé»˜è®¤1
}

interface VolcengineRequestConfig {
  reqid: string;
  text: string;
  text_type: 'plain' | 'ssml';
  operation: 'query'; // 'query' for real-time synthesis
  with_frontend?: 0 | 1; // 1 to get phonemes and word timestamps
  frontend_type?: 'unitTson'; // Required if with_frontend is 1
  with_timestamp?: 0 | 1; // 1 to enable timestamps in 'addition.frontend'
  instance_id?: string; // Add instance_id to the request payload
}

interface VolcengineTTSApiRequest {
  app: VolcengineAppConfig;
  user: VolcengineUserConfig;
  audio: VolcengineAudioConfig;
  request: VolcengineRequestConfig;
}

// Timestamp related interfaces (based on observed API responses)
export interface WordTimestamp {
  word: string;
  start_time: number; // in seconds
  end_time: number;   // in seconds
  unit_type: 'text' | 'mark';
}

export interface PhonemeTimestamp {
  phone: string;
  start_time: number; // in seconds
  end_time: number;   // in seconds
}

export interface FrontendTimestampData {
  words: WordTimestamp[];
  phonemes: PhonemeTimestamp[];
  // The full unitTson structure is complex, these are the most relevant parts for timing.
}

interface VolcengineTTSResponseAddition {
  duration?: string; // duration in milliseconds
  first_pkg?: string;
  frontend?: FrontendTimestampData; // Timestamps are here if requested
  description?: string; // May contain pinyin, etc.
  // other fields like unitTson might be present
}

interface VolcengineTTSApiResponse {
  reqid: string;
  code: number; // 0 for success, other values for errors (e.g., 3000 also seems to be success based on logs)
  operation: string;
  message: string;
  sequence: number;
  data?: string; // Base64 encoded audio data
  addition?: VolcengineTTSResponseAddition;
}

// --- Configuration ---

const VOLCENGINE_TTS_API_URL = 'https://openspeech.bytedance.com/api/v1/tts';

// Voice type mapping
// --- Utility Function ---

export interface VolcengineSynthesizeParams {
  text: string;
  appId: string;
  accessToken: string; // Used for Authorization: Bearer header
  cluster: string;
  voiceType: string; // This is the actual voice_type for the API request
  instanceId: string;
  enableTimestamps?: boolean;
  encoding?: 'mp3' | 'pcm' | 'wav';
  speedRatio?: number;
  volumeRatio?: number;
  pitchRatio?: number;
  emotion?: string;         // éŸ³è‰²æƒ…æ„Ÿ
  enableEmotion?: boolean;  // æ˜¯å¦å¯ç”¨æƒ…æ„Ÿ
  emotionScale?: number;    // æƒ…ç»ªå€¼å¼ºåº¦
  loudnessRatio?: number;   // éŸ³é‡è°ƒèŠ‚
  // æ–°å¢SSMLç›¸å…³å‚æ•°
  enableSSML?: boolean;     // æ˜¯å¦å¯ç”¨SSML
  autoEnhanceSSML?: boolean; // æ˜¯å¦è‡ªåŠ¨å¢å¼ºSSML
  speakerRole?: string;     // è¯´è¯äººè§’è‰²ï¼Œç”¨äºSSMLä¼˜åŒ–
}

export interface SynthesizedAudioResult {
  audioBuffer: ArrayBuffer | null;
  timestamps: FrontendTimestampData | null;
  durationMs?: number | null; // Duration in milliseconds, if available
  error?: string;
  rawResponse?: any; // Added for detailed error logging
}

export async function synthesizeSpeechVolcengine(params: VolcengineSynthesizeParams): Promise<SynthesizedAudioResult> {
  const {
    text,
    appId,
    accessToken,
    cluster,
    voiceType, // This is the actual voice_type to be used in the API request
    instanceId,
    enableTimestamps,
    encoding = 'mp3',
    speedRatio = DEFAULT_TTS_CONFIG.speedRatio,
    volumeRatio = DEFAULT_TTS_CONFIG.volumeRatio,
    pitchRatio = DEFAULT_TTS_CONFIG.pitchRatio,
    emotion = DEFAULT_TTS_CONFIG.emotion,        // ä½¿ç”¨é…ç½®æ–‡ä»¶çš„é»˜è®¤æƒ…æ„Ÿ
    enableEmotion = true,     // é»˜è®¤å¯ç”¨æƒ…æ„Ÿ
    emotionScale = DEFAULT_TTS_CONFIG.emotionScale,    // ä½¿ç”¨é…ç½®æ–‡ä»¶çš„æƒ…ç»ªå¼ºåº¦
    loudnessRatio = DEFAULT_TTS_CONFIG.loudnessRatio,   // ä½¿ç”¨é…ç½®æ–‡ä»¶çš„éŸ³é‡è®¾ç½®
    // SSMLç›¸å…³å‚æ•°
    enableSSML = false,
    autoEnhanceSSML = false,
    speakerRole = 'podcast_host'
  } = params;

  // å¤„ç†SSMLå¢å¼º
  let processedText = text;
  let textType: 'plain' | 'ssml' = 'plain';
  
  if (enableSSML || autoEnhanceSSML) {
    // è·å–SSMLæ¨è
    const recommendation = getSSMLRecommendationForPodcast(text.length, 1, text);
    
    if (autoEnhanceSSML && recommendation.shouldUseSSML) {
      console.log('[VolcengineTTS] è‡ªåŠ¨å¯ç”¨SSMLå¢å¼º:', recommendation.reasons);
      processedText = enhanceTextWithSSML(text, {
        enableBreaks: true,
        enableEmphasis: true,
        enableNumberOptimization: true,
        speakerRole
      });
      textType = 'ssml';
    } else if (enableSSML) {
      // å¦‚æœæ–‡æœ¬å·²ç»åŒ…å«SSMLæ ‡ç­¾ï¼ŒéªŒè¯å¹¶æ¸…ç†
      if (text.includes('<speak>') || text.includes('<') && text.includes('>')) {
        const ssmlValidation = validateAndCleanSSML(text);
        if (!ssmlValidation.isValid) {
          console.warn('[VolcengineTTS] SSMLéªŒè¯è­¦å‘Š:', ssmlValidation.errors);
        }
        processedText = ssmlValidation.cleanedSSML;
        textType = 'ssml';
      } else {
        // ç®€å•æ–‡æœ¬ï¼ŒåŒ…è£…ä¸ºSSML
        processedText = `<speak>${text}</speak>`;
        textType = 'ssml';
      }
    }
    
    console.log('[VolcengineTTS] SSMLå¤„ç†ç»“æœ:', {
      original: text.substring(0, 50) + '...',
      processed: processedText.substring(0, 100) + '...',
      textType,
      enableSSML,
      autoEnhanceSSML
    });
  }

  // éªŒè¯å‚æ•°æ˜¯å¦åœ¨å®˜æ–¹æ–‡æ¡£è§„å®šçš„èŒƒå›´å†…
  const validation = validateTTSParams({
    emotionScale,
    loudnessRatio,
    speedRatio,
    volumeRatio,
    pitchRatio
  });

  if (!validation.isValid) {
    console.warn('[VolcengineTTS] å‚æ•°éªŒè¯è­¦å‘Š:', validation.errors);
  }

  const requestBody: VolcengineTTSApiRequest = {
    app: {
      appid: appId,
      token: accessToken, // Use the provided accessToken
      cluster: cluster,
    },
    user: {
      uid: uuidv4(),
    },
    audio: {
      voice_type: voiceType, // Directly use the provided voiceType
      encoding: encoding,
      speed_ratio: speedRatio,
      volume_ratio: volumeRatio,
      pitch_ratio: pitchRatio,
      emotion: emotion,
      enable_emotion: enableEmotion,
      emotion_scale: emotionScale,
      loudness_ratio: loudnessRatio,
    },
    request: {
      reqid: uuidv4(), 
      text: processedText,
      text_type: textType, 
      operation: 'query',
      instance_id: instanceId,
      with_frontend: enableTimestamps ? 1 : 0,
      frontend_type: enableTimestamps ? 'unitTson' : undefined,
      with_timestamp: enableTimestamps ? 1 : 0, // Changed from need_timestamps to with_timestamp
    },
  };

  try {
    const fetchOptions = {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer;${accessToken}`,
      },
      body: JSON.stringify(requestBody),
    };

    console.log('[VolcengineTTS] Sending request payload:', JSON.stringify(requestBody, null, 2));

    const response = await $fetch<VolcengineTTSApiResponse>(VOLCENGINE_TTS_API_URL, fetchOptions);

    // å¢å¼ºé”™è¯¯æ£€æµ‹ - æ ¹æ®ç«å±±å¼•æ“å®˜æ–¹æ–‡æ¡£çš„é”™è¯¯ç 
    if (response.code !== 0 && response.code !== 3000) {
      console.error('Volcengine TTS API Error:', response);
      
      // æ ¹æ®é”™è¯¯ç åˆ¤æ–­é—®é¢˜ç±»å‹
      let errorType = 'UNKNOWN';
      let errorMessage = response.message;
      
      switch (response.code) {
        case 4001:
          errorType = 'AUTHENTICATION_FAILED';
          errorMessage = 'è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥AppIDã€AccessTokenç­‰é…ç½®ä¿¡æ¯';
          break;
        case 4003:
          errorType = 'INSUFFICIENT_BALANCE';
          errorMessage = 'è´¦æˆ·ä½™é¢ä¸è¶³ï¼Œè¯·å……å€¼åå†è¯•';
          break;
        case 4004:
          errorType = 'QUOTA_EXCEEDED';
          errorMessage = 'è°ƒç”¨æ¬¡æ•°å·²è¾¾ä¸Šé™ï¼Œè¯·ç¨åå†è¯•æˆ–å‡çº§å¥—é¤';
          break;
        case 4005:
          errorType = 'PERMISSION_DENIED';
          errorMessage = 'æ²¡æœ‰æƒé™ä½¿ç”¨è¯¥åŠŸèƒ½ï¼Œè¯·æ£€æŸ¥è´¦æˆ·æƒé™è®¾ç½®';
          break;
        case 4006:
          errorType = 'INVALID_VOICE_TYPE';
          errorMessage = 'éŸ³è‰²ç±»å‹æ— æ•ˆæˆ–ä¸æ”¯æŒï¼Œè¯·æ£€æŸ¥voiceTypeå‚æ•°';
          break;
        case 5001:
          errorType = 'TEXT_TOO_LONG';
          errorMessage = 'æ–‡æœ¬è¿‡é•¿ï¼Œè¯·ç¼©çŸ­æ–‡æœ¬åé‡è¯•';
          break;
        case 5002:
          errorType = 'INVALID_PARAMETERS';
          errorMessage = 'å‚æ•°æ— æ•ˆï¼Œè¯·æ£€æŸ¥è¯·æ±‚å‚æ•°';
          break;
        default:
          errorType = 'API_ERROR';
          errorMessage = `APIé”™è¯¯ ${response.code}: ${response.message}`;
      }
      
      console.error(`[VolcengineTTS] é”™è¯¯ç±»å‹: ${errorType}`);
      console.error(`[VolcengineTTS] é”™è¯¯ä¿¡æ¯: ${errorMessage}`);
      
      // å¦‚æœæ˜¯æ¬ è´¹é—®é¢˜ï¼Œç‰¹åˆ«æ ‡è®°
      if (response.code === 4003) {
        console.error('ğŸ”´ [VolcengineTTS] æ£€æµ‹åˆ°æ¬ è´¹é—®é¢˜ï¼è¯·å‰å¾€ç«å±±å¼•æ“æ§åˆ¶å°å……å€¼');
      }
      
      return {
        audioBuffer: null,
        timestamps: null,
        durationMs: null,
        error: `${errorType}: ${errorMessage}`,
        rawResponse: response, // Store raw error response
      };
    }

    const audioBase64 = response.data || null;
    const timestamps = response.addition?.frontend || null;
    const durationMs = response.addition?.duration ? parseInt(response.addition.duration, 10) : null;

    if (!audioBase64) {
      console.error('No audio data found in response or data is not a string:', response.data);
      return {
        audioBuffer: null,
        timestamps: null,
        durationMs: null,
        error: 'No audio data found in response or data is not a string.',
        rawResponse: response, // Store raw response when audio data is missing
      };
    }

    const binaryString = atob(audioBase64);
    const len = binaryString.length;
    const bytes = new Uint8Array(len);
    for (let i = 0; i < len; i++) {
      bytes[i] = binaryString.charCodeAt(i);
    }
    console.log('Successfully decoded base64 audio data.');

    return {
      audioBuffer: bytes.buffer,
      timestamps: timestamps,
      durationMs: durationMs,
    };

  } catch (error: any) {
    console.error('Error synthesizing speech with Volcengine:', error);
    return {
      audioBuffer: null,
      timestamps: null,
      durationMs: null,
      error: `Error synthesizing speech: ${error.message}`,
      rawResponse: error, // Store raw error object on catch
    };
  }
}
